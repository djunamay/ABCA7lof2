{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344d9391-7fcf-42bf-9163-f4c7401bd654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import io\n",
    "import scipy as scipy\n",
    "import collections\n",
    "import scipy.sparse as sp_sparse\n",
    "import tables\n",
    "import time\n",
    "import numba as nb\n",
    "from numba import config\n",
    "from numba_progress import ProgressBar\n",
    "import ipdb\n",
    "\n",
    "from ABCA7lof2.aggregation import aggregate_fastqs\n",
    "\n",
    "config.THREADING_LAYER = 'workqueue'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051ae93b-20ae-48b2-b156-07846ca0cf16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing...\n",
      "aggregating D20-7432\n",
      "aggregating D20-7433\n",
      "aggregating D20-7434\n",
      "aggregating D20-7435\n",
      "aggregating D20-7436\n",
      "aggregating D20-7437\n",
      "aggregating D20-7438\n",
      "aggregating D20-7439\n",
      "aggregating D20-7440\n",
      "aggregating D20-7441\n",
      "aggregating D20-7442\n",
      "aggregating D20-7443\n",
      "aggregating D20-7444\n",
      "aggregating D20-7445\n",
      "aggregating D20-7446\n",
      "aggregating D20-7447\n",
      "aggregating D20-7448\n",
      "aggregating D20-7450\n",
      "aggregating D20-7451\n",
      "aggregating D20-7452\n",
      "aggregating D20-7453\n",
      "aggregating D20-7454\n",
      "aggregating D20-7455\n",
      "aggregating D20-7456\n",
      "aggregating D20-7457\n",
      "aggregating D20-7458\n",
      "aggregating D17-8792\n",
      "aggregating D17-8782\n",
      "aggregating D17-8796\n",
      "aggregating D17-8764\n",
      "aggregating D17-8776\n",
      "aggregating D17-8772\n",
      "aggregating D17-8768\n",
      "aggregating D17-8766\n",
      "aggregating D17-8758\n",
      "aggregating D17-8778\n",
      "aggregating D17-8756\n",
      "aggregating D17-8800\n",
      "aggregating D17-8790\n",
      "aggregating D17-8754\n",
      "aggregating D17-8760\n",
      "aggregating D17-8786\n",
      "saving metadata\n",
      "truncating arrays\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# define in and output paths\n",
    "path_to_outputs = '/home/gridsan/djuna/homer/github/ABCA7lof2/raw_data/cellranger_counts_out/aggr_out/'\n",
    "\n",
    "if not path.exists(path_to_outputs):\n",
    "    os.mkdir(path_to_outputs)\n",
    "    \n",
    "meta_path_individual = '/home/gridsan/djuna/homer/github/ABCA7lof2/raw_data/metadata/single_cell_individual_metadata.csv'\n",
    "counts_path_individual = '/home/gridsan/djuna/homer/github/ABCA7lof2/raw_data/cellranger_counts_out/'\n",
    "\n",
    "aggregate_fastqs(path_to_outputs, meta_path_individual, counts_path_individual, Ncells=300000, Ngenes=36601)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bece470-75c3-4cf3-aa86-e4d49557103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = './raw_data/cellranger_counts_out/aggr_out/counts.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec59dd3-c8eb-4d1d-83e6-5db62cbbf703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(p, 'r+').truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e73d66-70df-4bf4-b008-79551e68ccd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='./raw_data/cellranger_counts_out/aggr_out/counts.npy' mode='r+' encoding='ISO-8859-1'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0499646-0ce0-499a-835f-0a0d1061ff10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.truncate(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90273fe4-a53c-45ec-8527-55f8a349fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(features_path, np.empty(shape=3, dtype='str'))\n",
    "features_out = np.lib.format.open_memmap(features_path, mode='r+', dtype='str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a4cbc96f-eb46-4c38-94e9-a224cd9f0704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap(['', '', ''], dtype='<U1')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9726a0ce-75ba-478a-af7f-2f62c6c2ae82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', ''], dtype='<U1')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty(shape=3, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aaf8ed7a-f29e-4e40-94e1-d8e777e142bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.empty((2,5), dtype=object)\n",
    "x[0][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "26903174-e02b-4f8f-a7a0-95f362849aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][2] = 'string'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16d60ee-960a-42d8-84b5-e4454880ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import io\n",
    "import scipy as scipy\n",
    "import collections\n",
    "import scipy.sparse as sp_sparse\n",
    "import tables\n",
    "import time\n",
    "import numba as nb\n",
    "from numba_progress import ProgressBar\n",
    "import os\n",
    "\n",
    "\n",
    "def decode(numpy_array):\n",
    "    return np.array([numpy_array[x].decode(\"utf-8\") for x in range(len(numpy_array))])\n",
    "\n",
    "def write_matrix(ID, counts_path_individual, cell_counts, cell_meta, subset_meta, counter, features_id_out, features_name_out, barcodes_out, Ngenes, i):\n",
    "    #ipdb.set_trace()\n",
    "\n",
    "\n",
    "    print('loading matrix...')\n",
    "    matrix = get_matrix_from_h5(counts_path_individual + ID + '/outs/filtered_feature_bc_matrix.h5')\n",
    "    \n",
    "    mat_array = matrix.matrix.T.toarray()\n",
    "    temp_ncells = mat_array.shape[0]\n",
    "    \n",
    "    barcodes_out[counter:counter+temp_ncells]  = decode(np.array(matrix.barcodes))\n",
    "    start = i*Ngenes\n",
    "    stop = start+Ngenes\n",
    "    features_id_out[start:stop] = decode(np.array(matrix.feature_ref['id']))\n",
    "    features_name_out[start:stop] = decode(np.array(matrix.feature_ref['name']))\n",
    "    \n",
    "    print('writing to memmap...')\n",
    "    write_counts_to_memmap(mat_array, cell_counts, counter)\n",
    "    add_metadata(cell_meta, subset_meta, counter, temp_ncells)\n",
    "    \n",
    "    counter+=temp_ncells\n",
    "    \n",
    "    return counter\n",
    "\n",
    "@nb.njit(parallel=True)\n",
    "def write_counts_to_memmap(mat_array, cell_counts, counter):\n",
    "    for x in nb.prange(mat_array.shape[0]):\n",
    "        cell_counts[counter+x] = mat_array[x]\n",
    "\n",
    "def add_metadata(cell_meta, subset_meta, counter, temp_ncells):\n",
    "    for x in range(temp_ncells):\n",
    "        cell_meta[counter+x] = subset_meta\n",
    "        \n",
    "def get_metadata(meta, Library_ID, barcodes):\n",
    "    print('getting metadata...')\n",
    "    subset_meta = np.array(meta[meta['sample_id']==Library_ID])[0]\n",
    "    subset_meta = np.array([subset_meta,]*len(barcodes))\n",
    "    subset_meta = np.concatenate((barcodes[:,None], subset_meta), axis = 1)\n",
    "    \n",
    "    return subset_meta\n",
    "\n",
    "def aggregate_fastqs(path_to_outputs, meta_path_individual, counts_path_individual, Ncells=300000, Ngenes=36601):\n",
    "    print('preparing...')\n",
    "    # initiate empty counts matrix and load as memmap\n",
    "    counts_path = path_to_outputs + 'counts.npy'\n",
    "    np.save(counts_path, np.empty(shape=(Ncells, Ngenes), dtype='int32'))\n",
    "    cell_counts = np.lib.format.open_memmap(counts_path, mode='r+', dtype='int32', shape=(Ncells, Ngenes))\n",
    "\n",
    "    # load metadata and get sample IDs\n",
    "    ind_meta = pd.read_csv(meta_path_individual)\n",
    "    n_metavars = ind_meta.shape[1]\n",
    "    meta_path = path_to_outputs + 'metadata.npy'\n",
    "    cell_meta = np.empty(shape=(Ncells, n_metavars), dtype=object)\n",
    "    \n",
    "    # initiate barcodes and features\n",
    "    sample_ids = ind_meta['sample_id']\n",
    "    n_ind = len(sample_ids)\n",
    "    features_id_path = path_to_outputs + 'features_id.npy'\n",
    "    np.save(features_id_path, np.empty(shape=Ngenes*n_ind, dtype='str'))\n",
    "    features_id_out = np.lib.format.open_memmap(features_id_path, mode='r+', dtype='str')\n",
    "\n",
    "    features_name_path = path_to_outputs + 'features_name.npy'\n",
    "    np.save(features_name_path, np.empty(shape=Ngenes*n_ind, dtype='str'))\n",
    "    features_name_out = np.lib.format.open_memmap(features_name_path, mode='r+', dtype='str')\n",
    "\n",
    "    barcodes_path = path_to_outputs + 'barcodes.npy'\n",
    "    np.save(barcodes_path, np.empty(shape=Ncells, dtype='str'))\n",
    "    barcodes_out = np.lib.format.open_memmap(barcodes_path, mode='r+', dtype='str')\n",
    " \n",
    "    # combine matrices\n",
    "    counter = 0    \n",
    "    counter = combine_matrices(sample_ids, cell_meta, ind_meta, cell_counts, counts_path_individual, features_id_out, features_name_out, barcodes_out, counter, Ngenes)\n",
    "\n",
    "    # save metadata\n",
    "    np.save(meta_path, cell_meta)\n",
    "    \n",
    "    # truncate arrays                 \n",
    "    remove = Ncells-counter\n",
    "    truncate(counts_path, cell_counts.size - remove * cell_counts[0].size)   \n",
    "    truncate(meta_path, cell_meta.size - remove * cell_meta[0].size)   \n",
    "    truncate(barcodes_path, barcodes_out.size - remove * barcodes_out[0].shape)   \n",
    "                                             \n",
    "def combine_matrices(sample_ids, cell_meta, ind_meta, cell_counts, counts_path_individual, features_id_out, features_name_out, barcodes_out, counter, Ngenes):\n",
    "    \n",
    "    for i in (range(len(sample_ids))):\n",
    "        ID = sample_ids[i]\n",
    "        print('aggregating ' + str(ID))\n",
    "        subset_meta = np.array(ind_meta[ind_meta['sample_id']==ID])[0]\n",
    "        counter = write_matrix(ID, counts_path_individual, cell_counts, cell_meta, subset_meta, counter, features_id_out, features_name_out, barcodes_out, Ngenes, i)\n",
    "    return counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1422f54e-bc3e-4ada-9e9c-4aefb9d88493",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "5506840056 requested and 0 written",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: 5506840056 requested and 0 written"
     ]
    }
   ],
   "source": [
    "cell_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7238b63e-8870-4d75-8b76-f6d5442c331d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2557"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(all_data[:counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e976a52-6743-463a-975d-e4eb8a15aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading hd5..\n"
     ]
    }
   ],
   "source": [
    "matrix = get_matrix_from_h5(path_to_counts + 'D20-7432' + '/outs/filtered_feature_bc_matrix.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd0378fe-1889-4913-84b5-ac9d849c62e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1840, 36601)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.matrix.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22002ac-917b-4ff4-bf6b-1cbea7b97cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b3494f-ee25-46a0-9f2d-6662954b759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing matrix...\n",
      "loading hd5..\n",
      "writing to memmap...\n",
      "getting metadata...\n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv(path_to_meta)\n",
    "all_counts = np.memmap(matrix_path, mode = 'w+', shape = (3000000, 36601), dtype = 'int32')\n",
    "all_meta = np.empty([0,meta.shape[1]+1])\n",
    "sample_ids = np.array(meta['sample_id'])\n",
    "counter = 0\n",
    "initial_id = sample_ids[0]\n",
    "init_features, init_barcodes, counter = write_matrix(initial_id, path_to_counts, all_counts, counter)\n",
    "init_meta = get_metadata(meta, initial_id, init_barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8927687f-0616-4648-87b2-02f6e06438a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import io\n",
    "import scipy as scipy\n",
    "import collections\n",
    "import scipy.sparse as sp_sparse\n",
    "import tables\n",
    "import time\n",
    "import numba as nb\n",
    "from numba_progress import ProgressBar\n",
    "import os\n",
    "\n",
    "#TODO: add docstrings to each function\n",
    "def get_matrix_from_h5(filename):\n",
    "    print('loading hd5..')\n",
    "    #TODO: understand this function better - describe all the slots in the doc string\n",
    "    '''\n",
    "    function adapted from https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/h5_matrices\n",
    "    Args:\n",
    "        filename (str) : path pointing to the counts matrix (genes x cell) output by the cellranger count function\n",
    "        This file contains the counts for a single sample in a slot called 'matrix'\n",
    "        Corresponding cell barcodes (column-names) are in the slot called 'barcodes' (must be unique)\n",
    "    Returns:\n",
    "        #TODO: specify what is being returned\n",
    "    '''\n",
    "    CountMatrix = collections.namedtuple('CountMatrix', ['feature_ref', 'barcodes', 'matrix'])\n",
    "    with tables.open_file(filename, 'r') as f:\n",
    "        mat_group = f.get_node(f.root, 'matrix')\n",
    "        barcodes = f.get_node(mat_group, 'barcodes').read()\n",
    "        data = getattr(mat_group, 'data').read()\n",
    "        indices = getattr(mat_group, 'indices').read()\n",
    "        indptr = getattr(mat_group, 'indptr').read()\n",
    "        shape = getattr(mat_group, 'shape').read()\n",
    "        matrix = sp_sparse.csc_matrix((data, indices, indptr), shape=shape)\n",
    "        feature_ref = {}\n",
    "        feature_group = f.get_node(mat_group, 'features')\n",
    "        feature_ids = getattr(feature_group, 'id').read()\n",
    "        feature_names = getattr(feature_group, 'name').read()\n",
    "        feature_types = getattr(feature_group, 'feature_type').read()\n",
    "        feature_ref['id'] = feature_ids\n",
    "        feature_ref['name'] = feature_names\n",
    "        feature_ref['feature_type'] = feature_types\n",
    "        tag_keys = getattr(feature_group, '_all_tag_keys').read()\n",
    "        for key in tag_keys:\n",
    "            key = key.decode(\"utf-8\")\n",
    "            feature_ref[key] = getattr(feature_group, key).read()\n",
    "        return CountMatrix(feature_ref, barcodes, matrix)\n",
    "\n",
    "def decode(numpy_array):\n",
    "    return np.array([numpy_array[x].decode(\"utf-8\") for x in range(len(numpy_array))])\n",
    "\n",
    "def write_matrix(Library_ID, path_to_counts, all_counts, counter):\n",
    "    print('writing matrix...')\n",
    "    #ipdb.set_trace()\n",
    "    matrix = get_matrix_from_h5(path_to_counts + Library_ID + '/outs/filtered_feature_bc_matrix.h5')\n",
    "    barcodes = decode(np.array(matrix.barcodes))\n",
    "    features = np.concatenate((decode(np.array(matrix.feature_ref['id']))[:,None],decode(np.array(matrix.feature_ref['name']))[:,None]), axis = 1)\n",
    "    mat = matrix.matrix\n",
    "    mat_array = mat.toarray()\n",
    "    #start = time.time()\n",
    "    print('writing to memmap...')\n",
    "    #with ProgressBar(total=mat_array.shape[0]) as numba_progress:\n",
    "    write_to_memmap(mat_array, all_counts, counter)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    counter+=mat_array.shape[0]\n",
    "    return features, barcodes, counter\n",
    "\n",
    "@nb.njit(parallel=True)\n",
    "def write_to_memmap(mat_array, all_counts, counter):\n",
    "    '''\n",
    "    writes array object to memmap\n",
    "    Args:\n",
    "        mat_array:\n",
    "        all_counts:\n",
    "        counter:\n",
    "        progress_hook:\n",
    "    '''\n",
    "    for i in nb.prange(mat_array.shape[0]):\n",
    "        all_counts[counter+i] = mat_array[i]\n",
    "        #progress_hook.update(1)\n",
    "\n",
    "def get_metadata(meta, Library_ID, barcodes):\n",
    "    print('getting metadata...')\n",
    "    subset_meta = np.array(meta[meta['sample_id']==Library_ID])[0]\n",
    "    subset_meta = np.array([subset_meta,]*len(barcodes))\n",
    "    subset_meta = np.concatenate((barcodes[:,None], subset_meta), axis = 1)\n",
    "    return subset_meta\n",
    "\n",
    "def aggregate_fastqs(path_to_meta, path_to_counts, features_path, meta_path, matrix_path):\n",
    "    meta = pd.read_csv(path_to_meta)\n",
    "    all_counts = np.memmap(matrix_path, mode = 'w+', shape = (3000000, 36601), dtype = 'int32')\n",
    "    all_meta = np.empty([0,meta.shape[1]+1])\n",
    "    sample_ids = np.array(meta['sample_id'])\n",
    "\n",
    "    counter = 0\n",
    "    initial_id = sample_ids[0]\n",
    "    print('aggregating ' + str(initial_id))\n",
    "    init_features, init_barcodes, counter = write_matrix(initial_id, path_to_counts, all_counts, counter)\n",
    "    init_meta = get_metadata(meta, initial_id, init_barcodes)\n",
    "    all_meta = np.concatenate((all_meta, init_meta), axis = 0)\n",
    "    np.save(features_path,init_features)\n",
    "    print('done.')\n",
    "    \n",
    "    return all_counts\n",
    "    #combine_matrices(sample_ids, init_features, all_meta, meta, all_counts, counter, path_to_counts, meta_path, matrix_path)\n",
    "\n",
    "def combine_matrices(sample_ids, init_features, all_meta, meta, all_counts, counter, path_to_counts, meta_path, matrix_path):\n",
    "    for i in (range(len(sample_ids)-1)):\n",
    "        #print(sample_ids[i+1])\n",
    "        print('aggregating ' + str(sample_ids[i+1]))\n",
    "        features, barcodes, counter = write_matrix(sample_ids[i+1], path_to_counts, all_counts, counter)\n",
    "        meta_temp = get_metadata(meta, sample_ids[i+1], barcodes)\n",
    "        all_meta = np.concatenate((all_meta, meta_temp), axis = 0)\n",
    "        print('done')\n",
    "        if not np.array_equal(features, init_features):\n",
    "            raise ValueError('feature matrices are inconsistent for ' + sample_ids[i+1])\n",
    "            break\n",
    "    print('saving data')\n",
    "    all_counts[:counter].tofile(matrix_path)\n",
    "    np.save(meta_path, all_meta)\n",
    "    print('all done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0efefd4-1ef5-4deb-b472-f2bd4f94e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def write_to_memmap(x):\n",
    "    for i in nb.prange(x):\n",
    "        1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8fc23f-fe40-4933-adbb-5d30af9a7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(path_to_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a15c27-7aea-4dd0-8191-468633a6d592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      84.435318\n",
       "1      85.533196\n",
       "2      85.694730\n",
       "3      79.687885\n",
       "4      74.050650\n",
       "5      89.393566\n",
       "6     100.766598\n",
       "7      89.360712\n",
       "8      93.801506\n",
       "9      91.715264\n",
       "10     85.114305\n",
       "11     83.485284\n",
       "12    100.008214\n",
       "13     86.548939\n",
       "14     90.759754\n",
       "15     94.343600\n",
       "16     79.408624\n",
       "17     89.448323\n",
       "18     94.004107\n",
       "19     86.505133\n",
       "20     89.418207\n",
       "21     82.255989\n",
       "22     92.624230\n",
       "23     77.459274\n",
       "24     88.950034\n",
       "25     94.598220\n",
       "26     87.238877\n",
       "27     80.533881\n",
       "28     93.237509\n",
       "29     76.057495\n",
       "30     82.710472\n",
       "31     89.713895\n",
       "32     83.728953\n",
       "33     85.776865\n",
       "34     74.773443\n",
       "35     92.479124\n",
       "36     88.468172\n",
       "37     85.828884\n",
       "38     87.665982\n",
       "39     89.026694\n",
       "40     86.403833\n",
       "41     87.449692\n",
       "Name: age_death, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e9dde-cb12-43e1-8405-72e1bbf1bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "echo(f\"loading the data\", underline=True)\n",
    "meta, features, counts = get_data(args.meta_path, args.features_path, args.matrix_path)\n",
    "gene_names = features[:,-1].astype('U17').reshape(-1)\n",
    "meta_col_names = np.load(args.meta_col_names, allow_pickle=True)\n",
    "\n",
    " # filter by cells prior to annotation\n",
    "echo(f\"initial filtering of cells\", underline=True)\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(path_to_outputs+\"/output.pdf\")\n",
    "mito_index, total_counts, mito_fractions, filtered_meta, filtered_counts = filter_cells(gene_names, counts, meta, args.sample_size, args.lower_bound_counts, args.upper_bound_counts, pdf, args.mito_prefix, path_to_outputs)\n",
    "\n",
    "# annotate the major cell types\n",
    "echo(f\"annotating major cell types\", underline=True)\n",
    "annotations, marker_out, projected_matrix, predict, scores, marker_genes, marker_indices = get_major_annotations(args.marker_path, gene_names, filtered_counts, total_counts, args.sample_size, args.n_components_pca, args.n_components_gaussian, path_to_outputs, args.infer_N_markers)\n",
    "\n",
    "# filter by Gaussian logliklihood\n",
    "echo(f\"filtering by logliklihood\", underline=True)\n",
    "keep_cells_1 = filter_on_gaussian_logliklihood(scores)\n",
    "\n",
    "# filter by major cell type annotation\n",
    "echo(f\"intra-celltype filtering\", underline=True)\n",
    "individual_annotation = filtered_meta[:,1]\n",
    "keep_cells_2, keep_cells_mito, keep_cells_individual, keep_genes, keep_individuals = filter_cells_by_major_annotation(mito_fractions, total_counts, args.sample_size, predict, individual_annotation, filtered_counts)\n",
    "\n",
    "# compile everything into the final metadata\n",
    "echo(f\"compiling all the data\", underline=True)\n",
    "filtered_meta_final = np.concatenate((filtered_meta,(keep_cells_1&keep_cells_2).reshape(-1,1), keep_cells_mito.reshape(-1,1), keep_cells_individual.reshape(-1,1), predict.reshape(-1,1), scores.reshape(-1,1), annotations.reshape(-1,1), total_counts.reshape(-1,1), mito_fractions.reshape(-1,1)), axis = 1)\n",
    "meta_names = np.concatenate((meta_col_names, np.array(('keep_cells_all_per_celltype', 'keep_cells_mito_per_celltype', 'keep_cells_individual', 'predictions', 'gaussian_liklihood', 'annotations', 'total_counts', 'mito_fractions'))), axis = 0)\n",
    "\n",
    "# save\n",
    "echo(f\"saving all the data\", underline=True)\n",
    "save_all(path_to_outputs, filtered_meta_final, meta_names, keep_genes, gene_names, marker_indices, mito_index, projected_matrix, annotations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "py_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
